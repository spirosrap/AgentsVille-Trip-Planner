{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgentsVille Trip Planner - Project Assignment\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you'll implement an AI-powered travel planning agent for AgentsVille. The system will demonstrate advanced LLM reasoning techniques including:\n",
    "\n",
    "1. **Role-Based Prompting** - Your agent will act as a specialized travel planner\n",
    "2. **Chain-of-Thought Reasoning** - Step-by-step planning of itineraries\n",
    "3. **ReAct Prompting** - Thought â†’ Action â†’ Observation cycles\n",
    "4. **Reflexion** - Self-evaluation to correct mistakes and improve plans\n",
    "5. **Memory Management** - Maintaining context about user preferences and constraints\n",
    "\n",
    "You'll need to simulate external API calls to gather weather data, cultural events, restaurants, and activities. Then, process this information to create personalized travel itineraries based on group size, ages, interests, and other constraints.\n",
    "\n",
    "Your task is to build a travel agent that can plan the perfect AgentsVille vacation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.74.0\n",
      "  Using cached openai-1.74.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from openai==1.74.0) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai==1.74.0) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai==1.74.0) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai==1.74.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.74.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.74.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.74.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/agentsVille/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.74.0) (0.4.1)\n",
      "Using cached openai-1.74.0-py3-none-any.whl (644 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.82.1\n",
      "    Uninstalling openai-1.82.1:\n",
      "      Successfully uninstalled openai-1.82.1\n",
      "Successfully installed openai-1.74.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "\n",
    "%pip install openai==1.74.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Setup\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pprint import pformat\n",
    "\n",
    "from project_lib import compare_dicts_case_insensitive, do_chat_completion, print_in_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows how to use two functions we will use repeatedly in the rest of the notebook.\n",
    "\n",
    "* `print_in_box` - a function for printing text in a box with a title and dimensions. Additionally,\n",
    "    the `tab_level` parameter can be used to add indentation to the text.\n",
    "* `do_chat_completion` - a function for making API calls to the OpenAI Chat Completion API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ system ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ You are a helpful assistant.                                                                     â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ user ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Hello, how are you?                                                                              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ assistant ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "    â•‘ I'm good, thanks!                                                                            â•‘\n",
      "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ user ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ What is 2+2?                                                                                     â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ assistant ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "    â•‘ 2 + 2 equals 4.                                                                              â•‘\n",
      "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "# Show a simple example using the `print_in_box` and `do_chat_completion` functions\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm good, thanks!\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
    "]\n",
    "for m in messages:\n",
    "    print_in_box(\n",
    "        m[\"content\"],\n",
    "        title=m[\"role\"],\n",
    "        # We use different tab levels to help visualize the conversation\n",
    "        tab_level=1 if m[\"role\"] == \"assistant\" else 0,\n",
    "    )\n",
    "\n",
    "response = do_chat_completion(messages, temperature=0.4)\n",
    "print_in_box(response, title=\"assistant\", tab_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the BoolResponseAgent\n",
    "\n",
    "In the following cell, we create our first agent, the `BoolResponseAgent`. Here's an example of how to use it:\n",
    "\n",
    "```python\n",
    "bool_response_agent = BoolResponseAgent()\n",
    "bool_response_agent.get_response(\"Do tests make for more reliable code?\", num_calls=3)\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ BoolResponseAgent - Query  ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘ Do tests make for more reliable code?                                        â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ BoolResponseAgent - Response ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘ <think>Tests can help identify bugs and ensure code behaves as expected, â•‘\n",
    "    â•‘ which generally leads to more reliable code. However, the effectiveness  â•‘\n",
    "    â•‘ of tests depends on their quality and coverage. Therefore, while tests   â•‘\n",
    "    â•‘ can contribute to reliability, they do not guarantee it on their         â•‘\n",
    "    â•‘ own.</think>                                                             â•‘\n",
    "    â•‘ <response>True</response>                                                â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ BoolResponseAgent - Response ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘ <think>Tests can help identify bugs and ensure that code behaves as      â•‘\n",
    "    â•‘ expected, which can lead to more reliable code. However, the             â•‘\n",
    "    â•‘ effectiveness of tests depends on their quality and coverage. Therefore, â•‘\n",
    "    â•‘ while tests generally contribute to code reliability, they do not        â•‘\n",
    "    â•‘ guarantee it. </think>                                                   â•‘\n",
    "    â•‘ <response>True</response>                                                â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ BoolResponseAgent - Response ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘ <think>Tests can help identify bugs and ensure that code behaves as      â•‘\n",
    "    â•‘ expected, which can contribute to more reliable code. However, the       â•‘\n",
    "    â•‘ effectiveness of tests depends on their quality and coverage. Therefore, â•‘\n",
    "    â•‘ while tests generally improve reliability, they do not guarantee it.     â•‘\n",
    "    â•‘ </think>                                                                 â•‘\n",
    "    â•‘ <response>True</response>                                                â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ BoolResponseAgent - Final Response ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘ True                                                                     â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoolResponseAgent:\n",
    "    \"\"\"\n",
    "    An agent that processes yes/no questions and returns boolean responses.\n",
    "\n",
    "    This agent uses a language model to analyze questions and provide True, False,\n",
    "    or None responses. For ambiguous questions, it can make multiple calls to the\n",
    "    model and return the most common response. This is also known as self-\n",
    "    consistency prompting. See Wang et al. (2022) (https://arxiv.org/abs/2203.11171)\n",
    "    for more details.\n",
    "\n",
    "    Attributes:\n",
    "        name: Name identifier for the agent\n",
    "        quiet: Whether to suppress printed output\n",
    "        print_tab_level: Indentation level for printed output\n",
    "        temperature: Temperature parameter for LLM sampling\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a chatbot that will:\n",
    "    * receieve a question from the user\n",
    "    * if the question is a yes or no question, think about the response using <think> and </think> tags\n",
    "    * finally, respond with either <response>True</response> or <response>False</response>\n",
    "    * If you are not able to answer, respond with <response>None</response>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"BoolResponseAgent\",\n",
    "        quiet: bool = False,\n",
    "        print_tab_level: int = 0,\n",
    "        temperature: float = 0.4,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.quiet = quiet\n",
    "        self.print_tab_level = print_tab_level\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def _run_single_query(self, messages: list[dict[str, str]]) -> bool | None:\n",
    "        \"\"\"\n",
    "        Execute a single query to the language model and parse the response.\n",
    "\n",
    "        Uses do_chat_completion to generate a response from the provided messages.\n",
    "        Returns True, False, or None based on the model's response format.\n",
    "\n",
    "        Args:\n",
    "            messages: List of message dictionaries to send to the model\n",
    "            query_num: Query number for tracking multiple calls\n",
    "\n",
    "        Returns:\n",
    "            bool: True or False if the model gives a definitive answer\n",
    "            None: If the model cannot provide an answer\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the response doesn't contain a valid format\n",
    "        \"\"\"\n",
    "        from project_lib import do_chat_completion\n",
    "\n",
    "        response = do_chat_completion(messages, temperature=self.temperature)\n",
    "\n",
    "        if not self.quiet:\n",
    "            print_in_box(\n",
    "                response,\n",
    "                title=f\"{self.name} - Response\",\n",
    "                tab_level=self.print_tab_level + 1,\n",
    "            )\n",
    "\n",
    "        if \"<response>True</response>\" in response:\n",
    "            return True\n",
    "        elif \"<response>False</response>\" in response:\n",
    "            return False\n",
    "        elif \"<response>None</response>\" in response:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError(\"Invalid response from BoolResponseAgent\")\n",
    "\n",
    "    def get_response(self, query: str, num_calls: int = 1) -> bool | None:\n",
    "        \"\"\"\n",
    "        Get a boolean response to a query by running the query through the LLM.\n",
    "\n",
    "        Args:\n",
    "            query: The question to ask the LLM\n",
    "            num_calls: Number of times to call the LLM (for consensus)\n",
    "\n",
    "        Returns:\n",
    "            bool: True or False based on LLM response\n",
    "            None: If the LLM cannot determine an answer\n",
    "        \"\"\"\n",
    "        from collections import Counter\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ]\n",
    "        if not self.quiet:\n",
    "            print_in_box(\n",
    "                query, title=f\"{self.name} - Query \", tab_level=self.print_tab_level\n",
    "            )\n",
    "\n",
    "        responses = [self._run_single_query(messages) for _ in range(1, num_calls + 1)]\n",
    "        counter = Counter(responses)\n",
    "        most_common_response = counter.most_common(1)[0][0]\n",
    "\n",
    "        if not self.quiet:\n",
    "            print_in_box(\n",
    "                most_common_response,\n",
    "                title=f\"{self.name} - Final Response\",\n",
    "                tab_level=self.print_tab_level + 1,\n",
    "            )\n",
    "\n",
    "        return most_common_response\n",
    "\n",
    "\n",
    "# Quick tests to guide the development of the agent\n",
    "bool_response_agent = BoolResponseAgent()\n",
    "\n",
    "assert bool_response_agent.get_response(\"Are you a robot?\") is True\n",
    "assert bool_response_agent.get_response(\"Are you a human?\", num_calls=3) is False\n",
    "assert bool_response_agent.get_response(\"Is this statement false?\", num_calls=3) is None\n",
    "\n",
    "print(\"All tests passed! Congratulations! ğŸ¤—\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our base ChatAgent class\n",
    "\n",
    "In the following cell we will create the ChatAgent class. Here is how it will work:\n",
    "\n",
    "```python\n",
    "chat_agent = ChatAgent(\"Grace\")\n",
    "chat_agent.chat(\"Hello, how are you?\")\n",
    "```\n",
    "\n",
    "This will print the following for debugging purposes.\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ Grace - System Prompt ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘ You are a helpful assistant. Your name is Grace.                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ Grace - User Prompt ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘ Hello, how are you?                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[ Grace - Assistant Response ]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘ Hello! I'm just a program, so I don't have feelings, but I'm here and    â•‘\n",
    "    â•‘ ready to help you. How can I assist you today?                           â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "The call to `chat_agent.chat` will return the string \"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatAgent:\n",
    "    \"\"\"A chat agent that interacts with OpenAI's API to facilitate conversations.\n",
    "\n",
    "    This class manages chat history, formats system prompts, and handles\n",
    "    communication with OpenAI's chat completion API. It provides methods to\n",
    "    add messages, get responses, and maintain conversation context.\n",
    "\n",
    "    Attributes:\n",
    "        system_prompt_template (str): Template for the system prompt using {variable_name} placeholders.\n",
    "        messages (list): The history of messages in the conversation.\n",
    "        quiet (bool): Whether to suppress printing of messages.\n",
    "        name (str): The name of the chat agent.\n",
    "        print_tab_level (int): Base indentation level for printed messages.\n",
    "        template_kwargs (dict): Keyword arguments for formatting the system prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt_template = \"\"\"\n",
    "        You are a helpful assistant. Your name is {name}.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    def __init__(self, name=None, quiet=False, template_kwargs=None, print_tab_level=0):\n",
    "        self.quiet = quiet\n",
    "        self.name = name or self.__class__.__name__\n",
    "        self.print_tab_level = print_tab_level\n",
    "\n",
    "        self.template_kwargs = template_kwargs or {}\n",
    "        self.template_kwargs[\"name\"] = self.name\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        \"\"\"Add a message to the chat history.\n",
    "\n",
    "        Args:\n",
    "            role (str): The role of the message (\"system\", \"user\", or \"assistant\").\n",
    "            content (str): The content of the message.\n",
    "\n",
    "        If `quiet` is False, the message will be printed in a formatted box. It will\n",
    "        be formatted by the `print_tab_level` attribute. If the role is assistant,\n",
    "        the `print_tab_level` will be incremented by 1.\n",
    "        \"\"\"\n",
    "        if role not in [\"system\", \"user\", \"assistant\"]:\n",
    "            raise ValueError(f\"Invalid role: {role}\")\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "        if not self.quiet:\n",
    "            if role == \"system\":\n",
    "                print_in_box(\n",
    "                    content,\n",
    "                    f\"{self.name} - System Prompt\",\n",
    "                    tab_level=self.print_tab_level,\n",
    "                )\n",
    "            elif role == \"user\":\n",
    "                print_in_box(\n",
    "                    content,\n",
    "                    f\"{self.name} - User Prompt\",\n",
    "                    tab_level=self.print_tab_level,\n",
    "                )\n",
    "            elif role == \"assistant\":\n",
    "                print_in_box(\n",
    "                    content,\n",
    "                    f\"{self.name} - Assistant Response\",\n",
    "                    tab_level=self.print_tab_level + 1,\n",
    "                )\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the chat history and re-initialize with the system prompt.\n",
    "\n",
    "        This method clears all existing messages and adds the system prompt\n",
    "        formatted with the template_kwargs.\n",
    "        \"\"\"\n",
    "        from textwrap import dedent\n",
    "\n",
    "        self.messages = []\n",
    "        self.add_message(\n",
    "            \"system\",\n",
    "            dedent(self.system_prompt_template.format(**(self.template_kwargs or {}))),\n",
    "        )\n",
    "\n",
    "    def get_response(self, add_to_messages=True):\n",
    "        \"\"\"Get a response from the OpenAI API.\n",
    "\n",
    "        Args:\n",
    "            add_to_messages (bool, optional): Whether to add the response to the chat history\n",
    "            using the add_message method and the assistant role. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            str: The response from the OpenAI API.\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        from project_lib import do_chat_completion\n",
    "\n",
    "        response = do_chat_completion(\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        if add_to_messages:\n",
    "            self.add_message(\"assistant\", response)\n",
    "        return response\n",
    "\n",
    "    def chat(self, user_message):\n",
    "        \"\"\"Send a message to the chat and get a response.\n",
    "\n",
    "        Args:\n",
    "            user_message (str): The message to send to the chat.\n",
    "\n",
    "        Returns:\n",
    "            str: The response from the OpenAI API.\n",
    "        \"\"\"\n",
    "        self.add_message(\"user\", user_message)\n",
    "        return self.get_response(add_to_messages=True)\n",
    "\n",
    "\n",
    "# Quick tests to verify the chat agent works\n",
    "\n",
    "chat_agent = ChatAgent(\"Grace\")\n",
    "assert len(chat_agent.messages) == 1  # +1 (System prompt)\n",
    "\n",
    "chat_agent.chat(\"Hello, how are you?\")\n",
    "assert len(chat_agent.messages) == 3  # +2 (User prompt + Assistant response)\n",
    "\n",
    "resp = chat_agent.chat(\"What is 2+2? Respond using only words.\")\n",
    "assert \"four\" in resp.lower()\n",
    "assert len(chat_agent.messages) == 5  # +2 (User prompt + Assistant response)\n",
    "\n",
    "chat_agent.chat(\"My name is Ada\")\n",
    "assert len(chat_agent.messages) == 7  # +2 (User prompt + Assistant response)\n",
    "\n",
    "chat_agent.chat(\"What is the first letter of my name?\")  # This agent has memory\n",
    "assert len(chat_agent.messages) == 9  # +2 (User prompt + Assistant response)\n",
    "\n",
    "chat_agent.chat(\"What is the first letter of your name?\")  # This agent has memory\n",
    "assert len(chat_agent.messages) == 11  # +2 (User prompt + Assistant response)\n",
    "\n",
    "print(\"ğŸ‰ğŸ‰ğŸ‰ Yay! Tests passed! Congrats!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our vacation\n",
    "\n",
    "Let's encode the details of our vacation in JSON format. This will be useful for developing our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about out vacation\n",
    "vacation_info = {\n",
    "    \"travelers\": [\n",
    "        {\n",
    "            \"name\": \"Yuri\",\n",
    "            \"age\": 30,\n",
    "            \"interests\": [\"tennis\", \"cooking\"],\n",
    "            \"dietary_restrictions\": [\"nut allergies\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Hiro\",\n",
    "            \"age\": 25,\n",
    "            \"interests\": [\"reading\", \"music\"],\n",
    "            \"dietary_restrictions\": [\"vegetarian\"],\n",
    "        },\n",
    "    ],\n",
    "    \"destination\": \"AgentsVille\",\n",
    "    \"date_of_arrival\": \"2025-06-10\",\n",
    "    \"date_of_departure\": \"2025-06-11\",\n",
    "    \"budget\": 1000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Traveler Agent. That's Us!\n",
    "\n",
    "In order to create an agent/chatbot that will help users design an exciting vacation, it will be useful to create an agent that can respond to our chatbot programmatically as if it were one of our users. That's right, we are going to build an agent of ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "class Traveler(ChatAgent):\n",
    "    system_prompt_template = \"\"\"\n",
    "\n",
    "    TODO\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Quick tests to make sure our agent is working\n",
    "\n",
    "traveler = Traveler(template_kwargs={\"vacation_info\": vacation_info})\n",
    "\n",
    "\n",
    "traveler.chat(\"Hello, how are you?\")\n",
    "\n",
    "response = traveler.chat(\n",
    "    \"How many people are in your group? Answer with a number, e.g. 7\"\n",
    ")\n",
    "assert str(len(vacation_info[\"travelers\"])) in response, (\n",
    "    \"The response should contain the number of people in the group.\"\n",
    ")\n",
    "\n",
    "response = traveler.chat(\n",
    "    \"When is your last day of travel? Answer in YYYY-MM-DD format, e.g. 2000-01-01\"\n",
    ")\n",
    "assert vacation_info[\"date_of_departure\"] in response, (\n",
    "    \"The response should contain the last day of travel.\"\n",
    ")\n",
    "\n",
    "# Celebrate\n",
    "\n",
    "print(\n",
    "    f\"Traveler Agent successfully answered a few quesions! To put this in production, we'd expand on this dataset. This is an excellent start. Let's continue building!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring the output of LLMs\n",
    "\n",
    "The output of LLMs can be structured by prompting the LLM to output, e.g., in JSON format. Due to the stochastic nature of LLMs, these outputs do not always strictly adhere to proper JSON format, unless the LLM offering natively offers strict adherence to a structured format. For pedagogical purposes, we will write our own function to location and parse JSON from the output of a LLM.\n",
    "\n",
    "For example, consider the following output from a LLM:\n",
    "\n",
    "```text\n",
    "    Here is the data you requested:\n",
    "    ```json\n",
    "    {\n",
    "        \"name\": \"Turing\",\n",
    "        \"age\": 30,\n",
    "        \"city\": \"New York\"\n",
    "    }\n",
    "    ```\n",
    "```\n",
    "\n",
    "Our function will extract the JSON from this output and return it as a Python dictionary.\n",
    "\n",
    "```python\n",
    ">>> extract_json_from_output(output)\n",
    "{'name': 'Turing', 'age': 30, 'city': 'New York'}\n",
    "```\n",
    "\n",
    "Additionally, it will work with invalid JSON, such as:\n",
    "\n",
    "```python\n",
    ">>> extract_json_from_output('```json\\n{{\"a: 1}\\n```')\n",
    "{'a': 1}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def find_and_parse_json(resp: str, max_retries: int = 3) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Find and parse a JSON dictionary from a string, using chat completion if necessary.\n",
    "\n",
    "    Args:\n",
    "        resp (str): The string to search for JSON.\n",
    "        max_retries (int, optional): The maximum number of retries. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any] | None: The parsed JSON object, or None if no JSON was found.\n",
    "\n",
    "    If the JSON is invalid, the function will retry up to max_retries times.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    from project_lib import do_chat_completion\n",
    "\n",
    "    pattern = r\"\\{.*\\}\"\n",
    "\n",
    "    match = re.search(pattern, resp, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            if max_retries <= 0:\n",
    "                print(\"âŒ Failed to parse JSON\")\n",
    "                return None\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You extract and properly format JSON given a string.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": resp},\n",
    "            ]\n",
    "\n",
    "            resp = do_chat_completion(messages)\n",
    "\n",
    "            return find_and_parse_json(resp, max_retries=max_retries - 1)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Test cases\n",
    "assert find_and_parse_json('```json\\n{\"a\": 1}\\n```') == {\"a\": 1}\n",
    "assert find_and_parse_json('{\"a\": 1}') == {\"a\": 1}\n",
    "assert find_and_parse_json('```json\\n{{\"a: 1}\\n```') == {\n",
    "    \"a\": 1\n",
    "}  # An extra opening brace\n",
    "\n",
    "print(\"âœ… All tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the OnboardingAgent\n",
    "\n",
    "Next we will create the onboarding agent, which will speak with our traveler (agent). For example:\n",
    "\n",
    "\n",
    "```python\n",
    ">>> onboarding_agent = OnboardingAgent()\n",
    ">>> traveler = Traveler(template_kwargs={\"vacation_info\": vacation_info})\n",
    "\n",
    ">>> gathered_vacation_info = onboarding_agent.gather_vacation_info(traveler_agent=traveler)\n",
    "```\n",
    "\n",
    "This will return a dictionary of the vacation information, ideally identical to `vacation_info`, though in practice the LLM may slightly modify it (e.g. capitalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnboardingAgent(ChatAgent):\n",
    "    system_prompt_template = \"\"\"\n",
    "    \n",
    "    TODO\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def gather_vacation_info(\n",
    "        self, traveler_agent: ChatAgent, starting_msg=\"Hello\", max_turns: int = 20\n",
    "    ) -> dict[str, Any] | None:\n",
    "        \"\"\"\n",
    "        Conducts a conversation between the onboarding agent and traveler agent to gather vacation information.\n",
    "\n",
    "        Args:\n",
    "            traveler_agent: The agent representing the traveler providing vacation details\n",
    "            starting_msg: Initial message to start the conversation (default: \"Hello\")\n",
    "            max_turns: Maximum number of conversation turns before timing out (default: 20)\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the gathered vacation information or None if unsuccessful\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the conversation exceeds the maximum number of turns without completion\n",
    "        \"\"\"\n",
    "        onboarding_agent = self\n",
    "        traveler = traveler_agent\n",
    "\n",
    "        msg = starting_msg\n",
    "\n",
    "        for _ in range(max_turns):\n",
    "            msg = onboarding_agent.chat(msg)\n",
    "\n",
    "            final_answer = find_and_parse_json(msg)\n",
    "            if final_answer:\n",
    "                return final_answer\n",
    "\n",
    "            msg = traveler.chat(msg)\n",
    "\n",
    "        raise ValueError(f\"Failed to complete onboarding after {max_turns} turns.\")\n",
    "\n",
    "\n",
    "# Run tests\n",
    "onboarding_agent = OnboardingAgent()\n",
    "traveler = Traveler(template_kwargs={\"vacation_info\": vacation_info}, quiet=True)\n",
    "\n",
    "gathered_vacation_info = onboarding_agent.gather_vacation_info(traveler_agent=traveler)\n",
    "\n",
    "print_in_box(pformat(vacation_info), title=\"Vacation Info\")\n",
    "print_in_box(pformat(gathered_vacation_info), title=\"Final Answer\")\n",
    "\n",
    "assert compare_dicts_case_insensitive(vacation_info, gathered_vacation_info)\n",
    "print(\n",
    "    \"Congratuations! Your agent successfully gathered all the information needed! ğŸ‰ğŸ‰ğŸ‰\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the functions `get_weather` and `get_events`\n",
    "\n",
    "The functions `get_weather` and `get_events` (which we will turn into tools) are defined in the `project_lib` module using static data for the purposes of this project. Although these would be dynamic in a production environment, during development and testing, we would use lots of synthetic data for reproducible results. Let's take a look at how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `get_weather` function returns the weather for a given date and city.\n",
    "\n",
    "from project_lib import get_weather\n",
    "\n",
    "get_weather(date=\"2025-06-10\", city=\"AgentsVille\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `get_events` function returns the events for a given date and city.\n",
    "\n",
    "from project_lib import get_events\n",
    "\n",
    "get_events(date=\"2025-06-10\", city=\"AgentsVille\")[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `ItineraryAgent` class (Using ReAct)\n",
    "\n",
    "Let's make a new itinerary agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItineraryAgent(ChatAgent):\n",
    "    system_prompt_template = \"\"\"\n",
    "        \n",
    "        TODO\n",
    "    \"\"\"\n",
    "\n",
    "    def get_itinerary(self, vacation_info):\n",
    "        final_output = None\n",
    "        max_steps = 20\n",
    "\n",
    "        step_num = 0\n",
    "\n",
    "        self.add_message(\n",
    "            \"user\",\n",
    "            (\n",
    "                msg := f\"\"\"\n",
    "            Here is information on the trip collected by the Onboarding Agent:\n",
    "            {vacation_info}.\n",
    "            Please design a daily itinerary for the trip.\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "        while step_num < max_steps and final_output is None:\n",
    "            step_num += 1\n",
    "            self.add_message(\n",
    "                \"user\",\n",
    "                f\"Let's start the {step_num}th step of the ReAct cycle, starting with <thought>...</thought>.\",\n",
    "            )\n",
    "            resp = self.get_response()  # <thought>...</thought>\n",
    "            resp = self.get_response()  # <act>...</act>\n",
    "\n",
    "            # Parse the action\n",
    "            obj = find_and_parse_json(resp)\n",
    "\n",
    "            if obj[\"tool\"] == \"weather\":\n",
    "                tool_results = get_weather(date=obj[\"date\"], city=obj[\"city\"])\n",
    "            elif obj[\"tool\"] == \"events\":\n",
    "                tool_results = get_events(date=obj[\"date\"], city=obj[\"city\"])\n",
    "            elif obj[\"tool\"] == \"final_output\":\n",
    "                final_output = obj\n",
    "                break\n",
    "            else:\n",
    "                raise ValueError(\"Invalid action\")\n",
    "\n",
    "            # Add the observation to the message history\n",
    "            self.add_message(\n",
    "                \"user\",\n",
    "                f\"<observation>{tool_results}</observation>\",\n",
    "            )\n",
    "\n",
    "        return final_output\n",
    "\n",
    "\n",
    "# Quick test\n",
    "itinerary_agent = ItineraryAgent(quiet=False)\n",
    "\n",
    "final_itinerary_1 = itinerary_agent.get_itinerary(vacation_info=gathered_vacation_info)\n",
    "print_in_box(final_itinerary_1, title=\"Final Itinerary\")\n",
    "\n",
    "if final_itinerary_1 is not None:\n",
    "    print(\"Final itinerary generated successfully. Congratulations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But is this itinerary any good?\n",
    "\n",
    "We've successfully created an itinerary, but how do we know if it's any good?\n",
    "\n",
    "Now we will create some evaluation functions (sometimes called evals) to help us determine the quality of the itinerary. We will not only want our final output to be of the highest quality possible initially, but we also want to give the chance for the LLM to reflect on its own output and make improvements at a second pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at this itinerary. Is it everything you expected?\n",
    "\n",
    "final_itinerary_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Evaluation Functions (evals)\n",
    "\n",
    "We will now write a set of evaluation functions to check if the itinerary is valid. Our functions will combine both regular procedural code in Python as well as calls to the bool_response_agent to answer questions such as: \"Does the following activity match any of these interests?\"\n",
    "\n",
    "These evaluation functions will either pass (return None) or raise an AgentError with a message that our LLM can use to revise its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write some evaluation functions!\n",
    "\n",
    "\n",
    "class AgentError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def eval_city_matches(vacation_info, final_output):\n",
    "    \"\"\"Verifies that the destination city specified in vacation_info matches the city in final_output.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details including the destination city\n",
    "        final_output (dict): Contains the itinerary details including the city\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If the cities don't match\n",
    "    \"\"\"\n",
    "    if vacation_info[\"destination\"] != final_output[\"city\"]:\n",
    "        raise AgentError(\n",
    "            f\"Cities do not match: {vacation_info['destination']} != {final_output['city']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_start_end_dates_match(vacation_info, final_output):\n",
    "    \"\"\"Verifies that the arrival and departure dates in vacation_info match the start and end dates in final_output.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details including arrival and departure dates\n",
    "        final_output (dict): Contains the itinerary details including start and end dates\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If either the arrival date doesn't match the start date or the departure date doesn't match the end date\n",
    "    \"\"\"\n",
    "    if (\n",
    "        vacation_info[\"date_of_arrival\"] != final_output[\"start_date\"]\n",
    "        or vacation_info[\"date_of_departure\"] != final_output[\"end_date\"]\n",
    "    ):\n",
    "        raise AgentError(\n",
    "            f\"Dates do not match: {vacation_info['date_of_arrival']} != {final_output['start_date']} or {vacation_info['date_of_departure']} != {final_output['end_date']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_total_cost_is_accurate(vacation_info, final_output):\n",
    "    \"\"\"Verifies that the total cost stated in final_output matches the sum of all activity prices.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details\n",
    "        final_output (dict): Contains the itinerary details including activities with prices and total cost\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If the calculated total cost doesn't match the stated total cost\n",
    "    \"\"\"\n",
    "    actual_total_cost = 0\n",
    "\n",
    "    for itinerary_item in final_output[\"itinerary\"]:\n",
    "        for activity in itinerary_item[\"activities\"]:\n",
    "            actual_total_cost += int(activity[\"price\"])\n",
    "\n",
    "    stated_total_cost = int(final_output[\"total_cost\"])\n",
    "\n",
    "    if actual_total_cost != stated_total_cost:\n",
    "        raise AgentError(\n",
    "            f\"Stated total cost does not match calculated total cost: {actual_total_cost} != {stated_total_cost}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_itinerary_matches_interests_and_is_balanced(vacation_info, final_output):\n",
    "    \"\"\"Verifies that the itinerary includes activities matching each traveler's interests and is balanced among all travelers.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details including traveler information and their interests\n",
    "        final_output (dict): Contains the itinerary details including daily activities\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If any traveler has no matching activities or if one traveler has more than twice\n",
    "                   the number of matching activities compared to another traveler\n",
    "    \"\"\"\n",
    "    traveler_to_interests = {}\n",
    "    traveler_to_interest_hit_counts = {}\n",
    "\n",
    "    for traveler in vacation_info[\"travelers\"]:\n",
    "        traveler_to_interests[traveler[\"name\"]] = traveler[\"interests\"]\n",
    "        traveler_to_interest_hit_counts[traveler[\"name\"]] = 0\n",
    "\n",
    "    for traveler, interests in traveler_to_interests.items():\n",
    "        for itinerary_item in final_output[\"itinerary\"]:\n",
    "            for activity in itinerary_item[\"activities\"]:\n",
    "                query = f\"\"\"Does the following activity match any of these interests: {interests}?\\n\\nActivity: {activity}\"\"\"\n",
    "                activity_matches_traveler_interests = bool_response_agent.get_response(\n",
    "                    query\n",
    "                )\n",
    "                if activity_matches_traveler_interests:\n",
    "                    traveler_to_interest_hit_counts[traveler] += 1\n",
    "\n",
    "    # If any of the travelers have 0 matches, raise an error\n",
    "    for traveler, interest_hit_count in traveler_to_interest_hit_counts.items():\n",
    "        if interest_hit_count == 0:\n",
    "            raise AgentError(f\"Traveler {traveler} has no matches with the itinerary.\")\n",
    "\n",
    "    # If any traveller has more than twice the number of matched interests of any other traveller, raise an error\n",
    "    min_hit_count = min(traveler_to_interest_hit_counts.values())\n",
    "    max_hit_count = max(traveler_to_interest_hit_counts.values())\n",
    "    if max_hit_count > 2 * min_hit_count:\n",
    "        min_hit_count_traveler_name = min(\n",
    "            traveler_to_interest_hit_counts, key=traveler_to_interest_hit_counts.get\n",
    "        )\n",
    "        max_hit_count_traveler_name = max(\n",
    "            traveler_to_interest_hit_counts, key=traveler_to_interest_hit_counts.get\n",
    "        )\n",
    "        raise AgentError(\n",
    "            f\"Traveler {max_hit_count_traveler_name} has more than twice the number of matched interests of {min_hit_count_traveler_name}. {max_hit_count} is more than twice {min_hit_count}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_itinerary_does_not_recommend_outdoor_activities_during_inclimate_weather_conditions(\n",
    "    vacation_info, final_output\n",
    "):\n",
    "    \"\"\"Verifies that the itinerary does not recommend outdoor activities during inclement weather conditions.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details\n",
    "        final_output (dict): Contains the itinerary details including daily activities and weather conditions\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If any outdoor activities are scheduled during weather conditions that could ruin them\n",
    "    \"\"\"\n",
    "    activities_that_may_be_ruined_by_inclimate_weather = []\n",
    "    for itinerary_item in final_output[\"itinerary\"]:\n",
    "        weather = itinerary_item[\"weather\"]\n",
    "\n",
    "        inclimate_weather_prompt = f\"\"\"Does the following weather condition prevent outdoor activities?\\n\\nWeather: {weather}\"\"\"\n",
    "        inclimate_weather_response = bool_response_agent.get_response(\n",
    "            inclimate_weather_prompt\n",
    "        )\n",
    "        if not inclimate_weather_response:\n",
    "            continue\n",
    "\n",
    "        for activity in itinerary_item[\"activities\"]:\n",
    "            activity_is_outdoors = bool_response_agent.get_response(\n",
    "                f\"\"\"Is the following activity outdoors?\\n\\nActivity: {activity}\"\"\"\n",
    "            )\n",
    "            if not activity_is_outdoors:\n",
    "                continue\n",
    "\n",
    "            query = dedent(f\"\"\"\n",
    "                Could the following activity be ruined by the following weather condition?\n",
    "\n",
    "                Activity: {activity}\n",
    "                Weather: {weather}\"\"\")\n",
    "            activity_possibly_ruined = bool_response_agent.get_response(query)\n",
    "            if activity_possibly_ruined:\n",
    "                activities_that_may_be_ruined_by_inclimate_weather.append(activity)\n",
    "\n",
    "    if activities_that_may_be_ruined_by_inclimate_weather:\n",
    "        raise AgentError(\n",
    "            f\"Activities that may be ruined by the following weather conditions.\\n\\nActivities: {activities_that_may_be_ruined_by_inclimate_weather}\\n\\nWeather: {weather}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_itinerary_respects_dietary_restrictions(vacation_info, final_output):\n",
    "    \"\"\"Verifies that the itinerary respects the dietary restrictions of all travelers.\n",
    "\n",
    "    Args:\n",
    "        vacation_info (dict): Contains the vacation details including travelers and their dietary restrictions\n",
    "        final_output (dict): Contains the itinerary details including daily activities\n",
    "\n",
    "    Raises:\n",
    "        AgentError: If any activity involves eating or drinking that would definitely unsuitable for a traveler's dietary restrictions\n",
    "    \"\"\"\n",
    "    travelers_to_dietary_restrictions = {}\n",
    "    for traveler in vacation_info[\"travelers\"]:\n",
    "        travelers_to_dietary_restrictions[traveler[\"name\"]] = traveler[\n",
    "            \"dietary_restrictions\"\n",
    "        ]\n",
    "\n",
    "    for traveler, restrictions in travelers_to_dietary_restrictions.items():\n",
    "        if not restrictions:\n",
    "            continue\n",
    "        for itinerary_item in final_output[\"itinerary\"]:\n",
    "            for activity in itinerary_item[\"activities\"]:\n",
    "                activity_involves_eating_or_drinking = bool_response_agent.get_response(\n",
    "                    f\"\"\"Does the following activity involve eating or drinking?\\n\\nActivity: {activity}\"\"\"\n",
    "                )\n",
    "                if not activity_involves_eating_or_drinking:\n",
    "                    continue\n",
    "\n",
    "                query = dedent(f\"\"\"\n",
    "                    Would the following activity definitely be unsuitable for someone with the following dietary restrictions?\n",
    "\n",
    "                    Only consider foods that are explicitly mentioned in the activity description. If there is not enough\n",
    "                    information to make a decision, return False.\n",
    "\n",
    "                    Activity: {activity}\n",
    "                    Dietary Restrictions: {restrictions}\"\"\")\n",
    "                definitely_unsuitable = bool_response_agent.get_response(query)\n",
    "                if definitely_unsuitable is True:\n",
    "                    raise AgentError(\n",
    "                        f\"Activity {activity['name']} would be unsuitable for a traveler with the following dietary restrictions: {restrictions}\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# Let's get the evaluation results!\n",
    "\n",
    "EVAL_FUNCTIONS = [\n",
    "    eval_city_matches,\n",
    "    eval_start_end_dates_match,\n",
    "    eval_total_cost_is_accurate,\n",
    "    eval_itinerary_matches_interests_and_is_balanced,\n",
    "    eval_itinerary_does_not_recommend_outdoor_activities_during_inclimate_weather_conditions,\n",
    "    eval_itinerary_respects_dietary_restrictions,\n",
    "]\n",
    "\n",
    "\n",
    "def get_eval_results(vacation_info, final_output):\n",
    "    eval_results = []\n",
    "    for eval_fn in EVAL_FUNCTIONS:\n",
    "        try:\n",
    "            eval_fn(vacation_info, final_output)\n",
    "        except AgentError as e:\n",
    "            error_msg = str(e)\n",
    "            print_in_box(error_msg, title=\"Evaluation Error\")\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            eval_results.append(error_msg)\n",
    "    return eval_results\n",
    "\n",
    "\n",
    "eval_results = get_eval_results(\n",
    "    vacation_info=vacation_info, final_output=final_itinerary_1\n",
    ")\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ItineraryRevisionAgent: Reflecting on our mistakes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItineraryRevisionAgent(ChatAgent):\n",
    "    system_prompt = \"\"\"\n",
    "        \n",
    "        TODO\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def cost_calculator(cls, activities):\n",
    "        \"\"\"Calculate the total cost of all activities\"\"\"\n",
    "        total_cost = sum(activity.get(\"price\", 0) for activity in activities)\n",
    "        return {\"total_cost\": total_cost}\n",
    "\n",
    "    def get_itinerary(self, vacation_info, proposed_itinerary):\n",
    "        final_output = None\n",
    "        max_steps = 20\n",
    "\n",
    "        step_num = 0\n",
    "\n",
    "        evaluation_results = get_eval_results(vacation_info, proposed_itinerary)\n",
    "\n",
    "        self.add_message(\n",
    "            \"user\",\n",
    "            f\"\"\"\n",
    "            Here is information on the trip collected by the Onboarding Agent:\n",
    "            {vacation_info}.\n",
    "            \"\"\",\n",
    "        )\n",
    "        self.add_message(\n",
    "            \"user\",\n",
    "            f\"\"\"\n",
    "            Here is the proposed itinerary:\n",
    "            {proposed_itinerary}.\n",
    "            \"\"\",\n",
    "        )\n",
    "        self.add_message(\n",
    "            \"user\",\n",
    "            f\"\"\"\n",
    "            Here is the evaluation results:\n",
    "            {evaluation_results}.\n",
    "            Please resolve the issues cited in the evaluation results.\n",
    "            \"\"\",\n",
    "        )\n",
    "        while step_num < max_steps and final_output is None:\n",
    "            step_num += 1\n",
    "            self.add_message(\n",
    "                \"user\",\n",
    "                f\"Let's start the {step_num}th step of the ReAct cycle, starting with <thought>...</thought>.\"\n",
    "                \" Always reference one of the available tools you will use in the next step along with parameters values.\",\n",
    "            )\n",
    "            resp = self.get_response()  # <thought>...</thought>\n",
    "\n",
    "            self.add_message(\n",
    "                \"user\",\n",
    "                'Next, respond with <act>{\"tool\": \"tool_name\", \"param1\": \"value1\", \"param2\": \"value2\"}</act>.',\n",
    "            )  # Sometimes the LLM needs to be reminded of the next step.\n",
    "            resp = self.get_response()  # <act>...</act>\n",
    "\n",
    "            # Parse the action\n",
    "            obj = find_and_parse_json(resp)\n",
    "\n",
    "            if obj[\"tool\"] == \"weather\":\n",
    "                tool_results = get_weather(date=obj[\"date\"], city=obj[\"city\"])\n",
    "            elif obj[\"tool\"] == \"events\":\n",
    "                tool_results = get_events(date=obj[\"date\"], city=obj[\"city\"])\n",
    "            elif obj[\"tool\"] == \"total_cost_calculator\":\n",
    "                tool_results = self.total_cost_calculator(activities=obj[\"activities\"])\n",
    "            elif obj[\"tool\"] == \"final_output\":\n",
    "                final_output = obj\n",
    "                break\n",
    "            else:\n",
    "                raise ValueError(\"Invalid action\")\n",
    "\n",
    "            # Add the observation to the message history\n",
    "            self.add_message(\n",
    "                \"user\",\n",
    "                f\"<observation>{tool_results}</observation>\",\n",
    "            )\n",
    "\n",
    "        # update the total_cost, since LLMs may sometime struggle with math\n",
    "        actual_total_cost = 0\n",
    "\n",
    "        for itinerary_item in final_output[\"itinerary\"]:\n",
    "            for activity in itinerary_item[\"activities\"]:\n",
    "                actual_total_cost += int(activity[\"price\"])\n",
    "\n",
    "        final_output[\"total_cost\"] = actual_total_cost\n",
    "\n",
    "        return final_output\n",
    "\n",
    "\n",
    "# Quick test\n",
    "itinerary_revision_agent = ItineraryRevisionAgent(quiet=False)\n",
    "\n",
    "final_itinerary_2 = itinerary_revision_agent.get_itinerary(\n",
    "    vacation_info=gathered_vacation_info,\n",
    "    proposed_itinerary=final_itinerary_1,\n",
    ")\n",
    "print_in_box(final_itinerary_2, title=\"Final Itinerary\")\n",
    "\n",
    "if final_itinerary_2 is not None:\n",
    "    print(\n",
    "        \"Final itinerary generated successfully. Congratulations! Let's see if it passes the evaluation.\"\n",
    "    )\n",
    "\n",
    "    evaluation_results = get_eval_results(vacation_info, final_itinerary_2)\n",
    "    print_in_box(evaluation_results, title=\"Evaluation Results\")\n",
    "\n",
    "    if len(evaluation_results) == 0:\n",
    "        print(\n",
    "            \"Final itinerary passed all evaluations. Congratulations! You created an entire agentic system from scratch!\"\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError(\"Final itinerary failed some evaluations. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And, just for fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, just for fun!\n",
    "\n",
    "from project_lib import narrate_my_trip\n",
    "\n",
    "narrate_my_trip(vacation_info=gathered_vacation_info, itinerary=final_itinerary_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentsVille",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
